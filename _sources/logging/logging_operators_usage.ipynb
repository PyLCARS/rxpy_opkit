{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "517064e7",
   "metadata": {},
   "source": [
    "# RxPy OpKit: Logging Operators Guide\n",
    "\n",
    "This notebook demonstrates all the logging operators available in RxPy OpKit. These operators help you debug, monitor, and understand the behavior of your reactive streams."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1051b8d4",
   "metadata": {},
   "source": [
    "# Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f2f145ec-ac93-474b-ac58-704861064a32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project root: /media/storage/GShared/Todays_Projects/rxpy_opkit\n",
      "Source directory: /media/storage/GShared/Todays_Projects/rxpy_opkit/src\n",
      "Directory exists: True\n",
      "Source exists: True\n",
      "Successfully imported rxpy_opkit from: /media/storage/GShared/Todays_Projects/rxpy_opkit/src/rxpy_opkit/__init__.py\n"
     ]
    }
   ],
   "source": [
    "# Add project root and src to Python path\n",
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# Directly use the absolute path to the project root\n",
    "# This works both in notebooks and in scripts\n",
    "project_root = Path('/media/storage/GShared/Todays_Projects/rxpy_opkit')\n",
    "src_dir = project_root / 'src'\n",
    "\n",
    "# Print diagnostic information\n",
    "print(f\"Project root: {project_root}\")\n",
    "print(f\"Source directory: {src_dir}\")\n",
    "print(f\"Directory exists: {project_root.exists()}\")\n",
    "print(f\"Source exists: {src_dir.exists()}\")\n",
    "\n",
    "# In case the hard-coded path doesn't work, try to find the project root\n",
    "if not src_dir.exists():\n",
    "    print(\"Hard-coded path didn't work, trying to find project root...\")\n",
    "    try:\n",
    "        # When running as a script\n",
    "        script_path = Path(__file__).resolve()\n",
    "        project_root = script_path.parent.parent.parent\n",
    "        src_dir = project_root / 'src'\n",
    "        print(f\"Script-based project root: {project_root}\")\n",
    "    except NameError:\n",
    "        # When in Jupyter, try working up from current directory\n",
    "        cwd = Path.cwd()\n",
    "        print(f\"Current working directory: {cwd}\")\n",
    "        \n",
    "        # If we're in notebooks/logging, go up two directories\n",
    "        if cwd.name == 'logging' and cwd.parent.name == 'notebooks':\n",
    "            project_root = cwd.parent.parent\n",
    "        # If we're in notebooks, go up one directory\n",
    "        elif cwd.name == 'notebooks':\n",
    "            project_root = cwd.parent\n",
    "        # Otherwise assume we're at the project root\n",
    "        else:\n",
    "            project_root = cwd\n",
    "            \n",
    "        src_dir = project_root / 'src'\n",
    "        print(f\"Notebook-based project root: {project_root}\")\n",
    "\n",
    "\n",
    "# Add both project root and src to Python path if not already there\n",
    "if str(project_root) not in sys.path:\n",
    "    sys.path.insert(0, str(project_root))\n",
    "if str(src_dir) not in sys.path:\n",
    "    sys.path.insert(0, str(src_dir))\n",
    "\n",
    "# Verify the package can be imported\n",
    "try:\n",
    "    import rxpy_opkit\n",
    "    print(f\"Successfully imported rxpy_opkit from: {rxpy_opkit.__file__}\")\n",
    "except ImportError as e:\n",
    "    print(f\"Failed to import rxpy_opkit: {e}\")\n",
    "    print(f\"Python path: {sys.path}\")\n",
    "    raise\n",
    "\n",
    "import reactivex as rx\n",
    "from reactivex import operators as ops\n",
    "import time\n",
    "import random\n",
    "from loguru import logger\n",
    "\n",
    "# Import logging operators from rxpy_opkit\n",
    "from rxpy_opkit.logging_ops import (\n",
    "    log, marble_log, context_log, rich_log, perf_log, conditional_log,\n",
    "    debug_stream, timestamp_stream\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67f30944-dc96-486c-adbf-502843c14db5",
   "metadata": {},
   "source": [
    "# Logging (Loguru) Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d9b34d10-0751-4157-87cb-a5c63dbcf841",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Configure loguru for notebook output\n",
    "logger.remove()\n",
    "logger.add(\n",
    "    sys.stdout,\n",
    "    format=\"<green>{time:HH:mm:ss.SSS}</green> | <level>{level: <8}</level> | <cyan>{name}</cyan> - <level>{message}</level>\",\n",
    "    colorize=True,\n",
    "    level=\"INFO\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2ec465e-817f-4224-9927-8569bc4aa7a2",
   "metadata": {},
   "source": [
    "# Logging Operators from `rxpy-opkit`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "782b197b",
   "metadata": {},
   "source": [
    "## `log` - Basic Logging Operator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f30feee7",
   "metadata": {},
   "source": [
    "### Description and Behavior\n",
    "\n",
    "The `log` operator is the simplest logging operator that logs all events passing through a stream. It's perfect for basic debugging and understanding data flow.\n",
    "\n",
    "**Behavior Details:**\n",
    "- **On Next**: Logs each value with a counter and optional custom formatting\n",
    "- **On Complete**: Logs completion with total count of values processed\n",
    "- **On Error**: Logs error type and message\n",
    "- **Internal Errors**: Formatting errors are caught and logged without interrupting the stream"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "850fed74-c376-4bc5-b38f-de04067c23cb",
   "metadata": {
    "title": "Styling"
   },
   "source": [
    "```mermaid\n",
    "flowchart TD\n",
    "    subgraph \"Source Observable\"\n",
    "        SNext[\"on_next: value\"]\n",
    "        SComplete[\"on_completed\"]\n",
    "        SError[\"on_error: err\"]\n",
    "    end\n",
    "    \n",
    "    subgraph \"log Operator\"\n",
    "        LogValue[\"Log value with<br/>prefix and count\"]\n",
    "        LogError[\"Log error type<br/>and message\"]\n",
    "        LogComplete[\"Log completion<br/>with total count\"]\n",
    "        FormatValue[\"Format value<br/>(truncate if needed)\"]\n",
    "    end\n",
    "    \n",
    "    subgraph \"Subscriber\"\n",
    "        ONext[\"on_next: value<br/>(unchanged)\"]\n",
    "        OComplete[\"on_completed\"]\n",
    "        OError[\"on_error: err\"]\n",
    "    end\n",
    "    \n",
    "\n",
    "    SNext --> FormatValue\n",
    "    FormatValue --> LogValue\n",
    "    LogValue --> ONext\n",
    "    \n",
    "\n",
    "    SComplete --> LogComplete\n",
    "    LogComplete --> OComplete\n",
    "    \n",
    "\n",
    "    SError --> LogError\n",
    "    LogError --> OError\n",
    "    \n",
    "\n",
    "    style SNext fill:#e4f7fb,stroke:#333\n",
    "    style SComplete fill:#e4f7fb,stroke:#333\n",
    "    style SError fill:#e4f7fb,stroke:#333\n",
    "    \n",
    "    style LogValue fill:#f96,stroke:#333\n",
    "    style LogError fill:#f96,stroke:#333\n",
    "    style LogComplete fill:#f96,stroke:#333\n",
    "    style FormatValue fill:#f96,stroke:#333\n",
    "    \n",
    "    style ONext fill:#d5f5d5,stroke:#333\n",
    "    style OComplete fill:#d5f5d5,stroke:#333\n",
    "    style OError fill:#ffcccc,stroke:#333\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e14db1c",
   "metadata": {},
   "source": [
    "### When to Use/Avoid and Alternatives"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "124216ff",
   "metadata": {},
   "source": [
    "**When to Use:**\n",
    "- Quick debugging of data flow through operators\n",
    "- Understanding what values are being emitted\n",
    "- Counting items in a stream\n",
    "- Basic stream monitoring in development"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5b9fb02",
   "metadata": {},
   "source": [
    "**When to Avoid:**\n",
    "- Production environments (unless with appropriate log levels)\n",
    "- High-frequency streams (can flood logs)\n",
    "- When you need structured logging (use `context_log` instead)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fc35b91",
   "metadata": {},
   "source": [
    "**Alternatives:**\n",
    "- `do_action`: Use built-in `do_action` with custom lambda for simple logging\n",
    "- `context_log`: For structured logging with additional context\n",
    "- `conditional_log`: To reduce log volume by filtering what gets logged"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7192d84",
   "metadata": {},
   "source": [
    "### Nominal Usage Examples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee787b94",
   "metadata": {},
   "source": [
    "#### Basic Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bd75c536",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example: Basic log operator\n",
      "---------------------------\n",
      "\u001b[32m16:17:44.967\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mrxpy_opkit.logging_ops.logging_operators\u001b[0m - \u001b[1m[Input] [1] Value: 1\u001b[0m\n",
      "\u001b[32m16:17:44.967\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mrxpy_opkit.logging_ops.logging_operators\u001b[0m - \u001b[1m[Mapped] [1] Value: 10\u001b[0m\n",
      "\u001b[32m16:17:44.968\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mrxpy_opkit.logging_ops.logging_operators\u001b[0m - \u001b[1m[Input] [2] Value: 2\u001b[0m\n",
      "\u001b[32m16:17:44.968\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mrxpy_opkit.logging_ops.logging_operators\u001b[0m - \u001b[1m[Mapped] [2] Value: 20\u001b[0m\n",
      "\u001b[32m16:17:44.968\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mrxpy_opkit.logging_ops.logging_operators\u001b[0m - \u001b[1m[Input] [3] Value: 3\u001b[0m\n",
      "\u001b[32m16:17:44.968\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mrxpy_opkit.logging_ops.logging_operators\u001b[0m - \u001b[1m[Mapped] [3] Value: 30\u001b[0m\n",
      "\u001b[32m16:17:44.968\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mrxpy_opkit.logging_ops.logging_operators\u001b[0m - \u001b[1m[Filtered] [1] Value: 30\u001b[0m\n",
      "Final result: 30\n",
      "\u001b[32m16:17:44.968\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mrxpy_opkit.logging_ops.logging_operators\u001b[0m - \u001b[1m[Input] [4] Value: 4\u001b[0m\n",
      "\u001b[32m16:17:44.968\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mrxpy_opkit.logging_ops.logging_operators\u001b[0m - \u001b[1m[Mapped] [4] Value: 40\u001b[0m\n",
      "\u001b[32m16:17:44.969\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mrxpy_opkit.logging_ops.logging_operators\u001b[0m - \u001b[1m[Filtered] [2] Value: 40\u001b[0m\n",
      "Final result: 40\n",
      "\u001b[32m16:17:44.969\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mrxpy_opkit.logging_ops.logging_operators\u001b[0m - \u001b[1m[Input] [5] Value: 5\u001b[0m\n",
      "\u001b[32m16:17:44.969\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mrxpy_opkit.logging_ops.logging_operators\u001b[0m - \u001b[1m[Mapped] [5] Value: 50\u001b[0m\n",
      "\u001b[32m16:17:44.969\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mrxpy_opkit.logging_ops.logging_operators\u001b[0m - \u001b[1m[Filtered] [3] Value: 50\u001b[0m\n",
      "Final result: 50\n",
      "\u001b[32m16:17:44.969\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mrxpy_opkit.logging_ops.logging_operators\u001b[0m - \u001b[1m[Input] Completed after 5 values\u001b[0m\n",
      "\u001b[32m16:17:44.970\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mrxpy_opkit.logging_ops.logging_operators\u001b[0m - \u001b[1m[Mapped] Completed after 5 values\u001b[0m\n",
      "\u001b[32m16:17:44.970\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mrxpy_opkit.logging_ops.logging_operators\u001b[0m - \u001b[1m[Filtered] Completed after 3 values\u001b[0m\n",
      "Stream completed\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<reactivex.disposable.disposable.Disposable at 0x77812abfe650>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Basic example demonstrating log operator\n",
    "source = rx.of(1, 2, 3, 4, 5)\n",
    "\n",
    "# Add logging at different points in the pipeline\n",
    "result = source.pipe(\n",
    "    log(\"Input\"),\n",
    "    ops.map(lambda x: x * 10),\n",
    "    log(\"Mapped\"),\n",
    "    ops.filter(lambda x: x > 25),\n",
    "    log(\"Filtered\")\n",
    ")\n",
    "\n",
    "print(\"Example: Basic log operator\")\n",
    "print(\"---------------------------\")\n",
    "result.subscribe(\n",
    "    on_next=lambda i: print(f\"Final result: {i}\"),\n",
    "    on_completed=lambda: print(\"Stream completed\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24a7f16e",
   "metadata": {},
   "source": [
    "```mermaid\n",
    "sequenceDiagram\n",
    "    participant Source\n",
    "    participant Log1 as log(\"Input\")\n",
    "    participant Map as map(x*10)\n",
    "    participant Log2 as log(\"Mapped\")\n",
    "    participant Filter as filter(>25)\n",
    "    participant Log3 as log(\"Filtered\")\n",
    "    participant Observer\n",
    "    \n",
    "    Source->>Log1: 1\n",
    "    Note over Log1: [Input] [1] Value: 1\n",
    "    Log1->>Map: 1\n",
    "    Map->>Log2: 10\n",
    "    Note over Log2: [Mapped] [1] Value: 10\n",
    "    Log2->>Filter: 10\n",
    "    Note over Filter: 10 <= 25, filtered out\n",
    "    \n",
    "    Source->>Log1: 2\n",
    "    Note over Log1: [Input] [2] Value: 2\n",
    "    Log1->>Map: 2\n",
    "    Map->>Log2: 20\n",
    "    Note over Log2: [Mapped] [2] Value: 20\n",
    "    Log2->>Filter: 20\n",
    "    Note over Filter: 20 <= 25, filtered out\n",
    "    \n",
    "    Source->>Log1: 3\n",
    "    Note over Log1: [Input] [3] Value: 3\n",
    "    Log1->>Map: 3\n",
    "    Map->>Log2: 30\n",
    "    Note over Log2: [Mapped] [3] Value: 30\n",
    "    Log2->>Filter: 30\n",
    "    Filter->>Log3: 30\n",
    "    Note over Log3: [Filtered] [1] Value: 30\n",
    "    Log3->>Observer: 30\n",
    "    \n",
    "    Source->>Log1: complete\n",
    "    Note over Log1: [Input] Completed after 5 values\n",
    "    Log1->>Map: complete\n",
    "    Map->>Log2: complete\n",
    "    Note over Log2: [Mapped] Completed after 5 values\n",
    "    Log2->>Filter: complete\n",
    "    Filter->>Log3: complete\n",
    "    Note over Log3: [Filtered] Completed after 3 values\n",
    "    Log3->>Observer: complete\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0a78cee",
   "metadata": {},
   "source": [
    "#### Custom Formatting Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0ae4b0c5",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Example: Custom Value Formatting\n",
      "--------------------------------\n",
      "\u001b[32m16:17:44.973\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mrxpy_opkit.logging_ops.logging_operators\u001b[0m - \u001b[1m[Users] [1] Value: User(id=1, name=Alice)\u001b[0m\n",
      "\u001b[32m16:17:44.974\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mrxpy_opkit.logging_ops.logging_operators\u001b[0m - \u001b[1m[Names] [1] Value: ALICE\u001b[0m\n",
      "\u001b[32m16:17:44.974\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mrxpy_opkit.logging_ops.logging_operators\u001b[0m - \u001b[1m[Users] [2] Value: User(id=2, name=Bob)\u001b[0m\n",
      "\u001b[32m16:17:44.974\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mrxpy_opkit.logging_ops.logging_operators\u001b[0m - \u001b[1m[Names] [2] Value: BOB\u001b[0m\n",
      "\u001b[32m16:17:44.974\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mrxpy_opkit.logging_ops.logging_operators\u001b[0m - \u001b[1m[Users] [3] Value: User(id=3, name=Charlie)\u001b[0m\n",
      "\u001b[32m16:17:44.975\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mrxpy_opkit.logging_ops.logging_operators\u001b[0m - \u001b[1m[Names] [3] Value: CHARLIE\u001b[0m\n",
      "\u001b[32m16:17:44.975\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mrxpy_opkit.logging_ops.logging_operators\u001b[0m - \u001b[1m[Users] Completed after 3 values\u001b[0m\n",
      "\u001b[32m16:17:44.975\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mrxpy_opkit.logging_ops.logging_operators\u001b[0m - \u001b[1m[Names] Completed after 3 values\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<reactivex.disposable.disposable.Disposable at 0x77812be94a10>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Custom formatter for complex objects\n",
    "def custom_formatter(value):\n",
    "    if isinstance(value, dict):\n",
    "        return f\"User(id={value.get('id')}, name={value.get('name')})\"\n",
    "    return str(value)\n",
    "\n",
    "# Source with dictionary values\n",
    "users = rx.of(\n",
    "    {\"id\": 1, \"name\": \"Alice\", \"email\": \"alice@example.com\"},\n",
    "    {\"id\": 2, \"name\": \"Bob\", \"email\": \"bob@example.com\"},\n",
    "    {\"id\": 3, \"name\": \"Charlie\", \"email\": \"charlie@example.com\"}\n",
    ")\n",
    "\n",
    "result = users.pipe(\n",
    "    log(\"Users\", value_formatter=custom_formatter),\n",
    "    ops.map(lambda u: u[\"name\"].upper()),\n",
    "    log(\"Names\")\n",
    ")\n",
    "\n",
    "print(\"\\nExample: Custom Value Formatting\")\n",
    "print(\"--------------------------------\")\n",
    "result.subscribe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "868346fa",
   "metadata": {},
   "source": [
    "### Error Handling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc4acad7",
   "metadata": {},
   "source": [
    "Common errors when using `log` operator:\n",
    "1. **Formatter errors**: Custom formatters may fail on unexpected value types\n",
    "2. **String conversion errors**: Some objects may not have proper string representations\n",
    "3. **Performance impact**: Logging every value in high-frequency streams\n",
    "\n",
    "**Best Practices:**\n",
    "- Use safe formatters that handle exceptions\n",
    "- Configure appropriate log levels for different environments\n",
    "- Consider `conditional_log` for high-frequency streams"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a895ed40",
   "metadata": {},
   "source": [
    "#### Example: Handling Formatter Errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ccf32746",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Example: Formatter Error Handling\n",
      "---------------------------------\n",
      "\u001b[32m16:17:44.978\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36mrxpy_opkit.logging_ops.logging_operators\u001b[0m - \u001b[31m\u001b[1m[Risky] Error: AttributeError: 'dict' object has no attribute 'data'\u001b[0m\n",
      "Stream error: 'dict' object has no attribute 'data'\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<reactivex.disposable.disposable.Disposable at 0x77812ac5b610>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Formatter that might fail\n",
    "def risky_formatter(value):\n",
    "    # This will fail if value doesn't have 'data' attribute\n",
    "    return f\"Data: {value.data}\"\n",
    "\n",
    "# Mix of values, some will cause formatter errors\n",
    "source = rx.of(\n",
    "    {\"data\": \"good\"},\n",
    "    \"bad_value\",  # This will cause formatter error\n",
    "    {\"data\": \"also_good\"}\n",
    ")\n",
    "\n",
    "result = source.pipe(\n",
    "    log(\"Risky\", value_formatter=risky_formatter)\n",
    ")\n",
    "\n",
    "print(\"\\nExample: Formatter Error Handling\")\n",
    "print(\"---------------------------------\")\n",
    "result.subscribe(\n",
    "    on_next=lambda x: print(f\"Received: {x}\"),\n",
    "    on_error=lambda e: print(f\"Stream error: {e}\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cdba0b8",
   "metadata": {},
   "source": [
    "## `marble_log` - ASCII Marble Diagram Logger"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f66deba",
   "metadata": {},
   "source": [
    "### Description and Behavior\n",
    "\n",
    "The `marble_log` operator creates ASCII marble diagrams to visualize the timing and sequence of events in a stream. It's excellent for understanding async behavior and timing.\n",
    "\n",
    "**Behavior Details:**\n",
    "- **On Next**: Adds a symbol to the timeline representing the value\n",
    "- **On Complete**: Shows completion marker `|` on the timeline\n",
    "- **On Error**: Shows error marker `X` on the timeline\n",
    "- **Internal Errors**: None expected (simple string operations)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb6ff79b-ed08-4433-b0a4-5c9344740d3b",
   "metadata": {
    "title": "Styling"
   },
   "source": [
    "```mermaid\n",
    "flowchart TD\n",
    "    subgraph \"Source Observable\"\n",
    "        SNext[\"on_next: value\"]\n",
    "        SComplete[\"on_completed\"]\n",
    "        SError[\"on_error: err\"]\n",
    "    end\n",
    "    \n",
    "    subgraph \"marble_log Operator\"\n",
    "        AddToTimeline[\"Add event to timeline\"]\n",
    "        SelectSymbol[\"Select symbol:<br/>• numbers: first digit<br/>• strings: first char<br/>• other: •\"]\n",
    "        PrintTimeline[\"Print timeline with<br/>dashes and symbols\"]\n",
    "        MarkComplete[\"Add | symbol\"]\n",
    "        MarkError[\"Add X symbol\"]\n",
    "    end\n",
    "    \n",
    "    subgraph \"Subscriber\"\n",
    "        ONext[\"on_next: value<br/>(unchanged)\"]\n",
    "        OComplete[\"on_completed\"]\n",
    "        OError[\"on_error: err\"]\n",
    "    end\n",
    "    \n",
    "\n",
    "    SNext --> SelectSymbol\n",
    "    SelectSymbol --> AddToTimeline\n",
    "    AddToTimeline --> PrintTimeline\n",
    "    PrintTimeline --> ONext\n",
    "    \n",
    "\n",
    "    SComplete --> MarkComplete\n",
    "    MarkComplete --> PrintTimeline\n",
    "    PrintTimeline --> OComplete\n",
    "    \n",
    "\n",
    "    SError --> MarkError\n",
    "    MarkError --> PrintTimeline\n",
    "    PrintTimeline --> OError\n",
    "    \n",
    "\n",
    "    style SNext fill:#e4f7fb,stroke:#333\n",
    "    style SComplete fill:#e4f7fb,stroke:#333\n",
    "    style SError fill:#e4f7fb,stroke:#333\n",
    "    \n",
    "    style AddToTimeline fill:#f96,stroke:#333\n",
    "    style SelectSymbol fill:#f96,stroke:#333\n",
    "    style PrintTimeline fill:#f96,stroke:#333\n",
    "    style MarkComplete fill:#f96,stroke:#333\n",
    "    style MarkError fill:#f96,stroke:#333\n",
    "    \n",
    "    style ONext fill:#d5f5d5,stroke:#333\n",
    "    style OComplete fill:#d5f5d5,stroke:#333\n",
    "    style OError fill:#ffcccc,stroke:#333\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92ee567c",
   "metadata": {},
   "source": [
    "### When to Use/Avoid and Alternatives"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff53db8d",
   "metadata": {},
   "source": [
    "**When to Use:**\n",
    "- Visualizing timing of async operations\n",
    "- Understanding operator behavior with delays\n",
    "- Teaching/demonstrating reactive concepts\n",
    "- Debugging race conditions or timing issues"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ac0cf71",
   "metadata": {},
   "source": [
    "**When to Avoid:**\n",
    "- Production code (it's a debugging tool)\n",
    "- Very long-running streams (timeline gets truncated)\n",
    "- When you need precise timing measurements (use `perf_log`)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "306f72b6",
   "metadata": {},
   "source": [
    "**Alternatives:**\n",
    "- `timestamp`: Built-in operator to add timestamps to values\n",
    "- `perf_log`: For precise performance measurements\n",
    "- External visualization tools for production monitoring"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c21ed287",
   "metadata": {},
   "source": [
    "### Nominal Usage Examples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "713ad77b",
   "metadata": {},
   "source": [
    "#### Basic Marble Diagram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "79c8a5b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m16:17:44.982\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mrxpy_opkit.logging_ops.logging_operators\u001b[0m - \u001b[1m         Source: ------------------------------ (START)\u001b[0m\n",
      "\u001b[32m16:17:44.982\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mrxpy_opkit.logging_ops.logging_operators\u001b[0m - \u001b[1m         Mapped: ------------------------------ (START)\u001b[0m\n",
      "\u001b[32m16:17:44.982\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mrxpy_opkit.logging_ops.logging_operators\u001b[0m - \u001b[1m       Filtered: ------------------------------ (START)\u001b[0m\n",
      "Example: Marble Diagram Visualization\n",
      "------------------------------------\n",
      "\u001b[32m16:17:45.183\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mrxpy_opkit.logging_ops.logging_operators\u001b[0m - \u001b[1m         Source: 0-----------------------------\u001b[0m\n",
      "\u001b[32m16:17:45.185\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mrxpy_opkit.logging_ops.logging_operators\u001b[0m - \u001b[1m         Mapped: 0-----------------------------\u001b[0m\n",
      "\u001b[32m16:17:45.187\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mrxpy_opkit.logging_ops.logging_operators\u001b[0m - \u001b[1m       Filtered: 0-----------------------------\u001b[0m\n",
      "\u001b[32m16:17:45.384\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mrxpy_opkit.logging_ops.logging_operators\u001b[0m - \u001b[1m         Source: 01----------------------------\u001b[0m\n",
      "\u001b[32m16:17:45.387\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mrxpy_opkit.logging_ops.logging_operators\u001b[0m - \u001b[1m         Mapped: 02----------------------------\u001b[0m\n",
      "\u001b[32m16:17:45.585\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mrxpy_opkit.logging_ops.logging_operators\u001b[0m - \u001b[1m         Source: 012---------------------------\u001b[0m\n",
      "\u001b[32m16:17:45.588\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mrxpy_opkit.logging_ops.logging_operators\u001b[0m - \u001b[1m         Mapped: 024---------------------------\u001b[0m\n",
      "\u001b[32m16:17:45.589\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mrxpy_opkit.logging_ops.logging_operators\u001b[0m - \u001b[1m       Filtered: 04----------------------------\u001b[0m\n",
      "\u001b[32m16:17:45.786\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mrxpy_opkit.logging_ops.logging_operators\u001b[0m - \u001b[1m         Source: 0123--------------------------\u001b[0m\n",
      "\u001b[32m16:17:45.789\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mrxpy_opkit.logging_ops.logging_operators\u001b[0m - \u001b[1m         Mapped: 0246--------------------------\u001b[0m\n",
      "\u001b[32m16:17:45.987\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mrxpy_opkit.logging_ops.logging_operators\u001b[0m - \u001b[1m         Source: 01234-------------------------\u001b[0m\n",
      "\u001b[32m16:17:45.989\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mrxpy_opkit.logging_ops.logging_operators\u001b[0m - \u001b[1m         Mapped: 02468-------------------------\u001b[0m\n",
      "\u001b[32m16:17:45.991\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mrxpy_opkit.logging_ops.logging_operators\u001b[0m - \u001b[1m       Filtered: 048---------------------------\u001b[0m\n",
      "\u001b[32m16:17:46.188\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mrxpy_opkit.logging_ops.logging_operators\u001b[0m - \u001b[1m         Source: 012345------------------------\u001b[0m\n",
      "\u001b[32m16:17:46.190\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mrxpy_opkit.logging_ops.logging_operators\u001b[0m - \u001b[1m         Mapped: 02468•------------------------\u001b[0m\n",
      "\u001b[32m16:17:46.389\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mrxpy_opkit.logging_ops.logging_operators\u001b[0m - \u001b[1m         Source: 0123456-----------------------\u001b[0m\n",
      "\u001b[32m16:17:46.392\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mrxpy_opkit.logging_ops.logging_operators\u001b[0m - \u001b[1m         Mapped: 02468••-----------------------\u001b[0m\n",
      "\u001b[32m16:17:46.393\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mrxpy_opkit.logging_ops.logging_operators\u001b[0m - \u001b[1m       Filtered: 048•--------------------------\u001b[0m\n",
      "\u001b[32m16:17:46.590\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mrxpy_opkit.logging_ops.logging_operators\u001b[0m - \u001b[1m         Source: 01234567----------------------\u001b[0m\n",
      "\u001b[32m16:17:46.592\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mrxpy_opkit.logging_ops.logging_operators\u001b[0m - \u001b[1m         Mapped: 02468•••----------------------\u001b[0m\n",
      "\u001b[32m16:17:46.791\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mrxpy_opkit.logging_ops.logging_operators\u001b[0m - \u001b[1m         Source: 012345678---------------------\u001b[0m\n",
      "\u001b[32m16:17:46.793\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mrxpy_opkit.logging_ops.logging_operators\u001b[0m - \u001b[1m         Mapped: 02468••••---------------------\u001b[0m\n",
      "\u001b[32m16:17:46.795\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mrxpy_opkit.logging_ops.logging_operators\u001b[0m - \u001b[1m       Filtered: 048••-------------------------\u001b[0m\n",
      "\u001b[32m16:17:46.992\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mrxpy_opkit.logging_ops.logging_operators\u001b[0m - \u001b[1m         Source: 0123456789--------------------\u001b[0m\n",
      "\u001b[32m16:17:46.994\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mrxpy_opkit.logging_ops.logging_operators\u001b[0m - \u001b[1m         Mapped: 02468•••••--------------------\u001b[0m\n",
      "\u001b[32m16:17:46.996\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mrxpy_opkit.logging_ops.logging_operators\u001b[0m - \u001b[1m         Source: 0123456789|------------------- (COMPLETED)\u001b[0m\n",
      "\u001b[32m16:17:46.997\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mrxpy_opkit.logging_ops.logging_operators\u001b[0m - \u001b[1m         Mapped: 02468•••••|------------------- (COMPLETED)\u001b[0m\n",
      "\u001b[32m16:17:46.998\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mrxpy_opkit.logging_ops.logging_operators\u001b[0m - \u001b[1m       Filtered: 048••|------------------------ (COMPLETED)\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Create an interval observable for timing visualization\n",
    "source = rx.interval(0.2).pipe(\n",
    "    ops.take(10),\n",
    "    marble_log(\"Source\", width=30),\n",
    "    ops.map(lambda x: x * 2),\n",
    "    marble_log(\"Mapped\", width=30),\n",
    "    ops.filter(lambda x: x % 4 == 0),\n",
    "    marble_log(\"Filtered\", width=30)\n",
    ")\n",
    "\n",
    "print(\"Example: Marble Diagram Visualization\")\n",
    "print(\"------------------------------------\")\n",
    "# This will show the marble diagram in real-time\n",
    "subscription = source.subscribe()\n",
    "time.sleep(2.5)  # Let it run\n",
    "subscription.dispose()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfd9dff3",
   "metadata": {},
   "source": [
    "#### Multiple Streams Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "693c982f",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m16:17:47.494\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mrxpy_opkit.logging_ops.logging_operators\u001b[0m - \u001b[1m       Stream A: ---------------------------------------- (START)\u001b[0m\n",
      "\u001b[32m16:17:47.497\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mrxpy_opkit.logging_ops.logging_operators\u001b[0m - \u001b[1m       Stream B: ---------------------------------------- (START)\u001b[0m\n",
      "\u001b[32m16:17:47.499\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mrxpy_opkit.logging_ops.logging_operators\u001b[0m - \u001b[1m         Merged: ---------------------------------------- (START)\u001b[0m\n",
      "\n",
      "Example: Multiple Stream Comparison\n",
      "-----------------------------------\n",
      "\u001b[32m16:17:47.702\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mrxpy_opkit.logging_ops.logging_operators\u001b[0m - \u001b[1m       Stream B: B---------------------------------------\u001b[0m\n",
      "\u001b[32m16:17:47.704\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mrxpy_opkit.logging_ops.logging_operators\u001b[0m - \u001b[1m         Merged: B---------------------------------------\u001b[0m\n",
      "\u001b[32m16:17:47.801\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mrxpy_opkit.logging_ops.logging_operators\u001b[0m - \u001b[1m       Stream A: A---------------------------------------\u001b[0m\n",
      "\u001b[32m16:17:47.804\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mrxpy_opkit.logging_ops.logging_operators\u001b[0m - \u001b[1m         Merged: BA--------------------------------------\u001b[0m\n",
      "\u001b[32m16:17:47.903\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mrxpy_opkit.logging_ops.logging_operators\u001b[0m - \u001b[1m       Stream B: BB--------------------------------------\u001b[0m\n",
      "\u001b[32m16:17:47.906\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mrxpy_opkit.logging_ops.logging_operators\u001b[0m - \u001b[1m         Merged: BAB-------------------------------------\u001b[0m\n",
      "\u001b[32m16:17:48.102\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mrxpy_opkit.logging_ops.logging_operators\u001b[0m - \u001b[1m       Stream A: AA--------------------------------------\u001b[0m\n",
      "\u001b[32m16:17:48.106\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mrxpy_opkit.logging_ops.logging_operators\u001b[0m - \u001b[1m         Merged: BABA------------------------------------\u001b[0m\n",
      "\u001b[32m16:17:48.105\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mrxpy_opkit.logging_ops.logging_operators\u001b[0m - \u001b[1m       Stream B: BBB-------------------------------------\u001b[0m\n",
      "\u001b[32m16:17:48.109\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mrxpy_opkit.logging_ops.logging_operators\u001b[0m - \u001b[1m         Merged: BABAB-----------------------------------\u001b[0m\n",
      "\u001b[32m16:17:48.306\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mrxpy_opkit.logging_ops.logging_operators\u001b[0m - \u001b[1m       Stream B: BBBB------------------------------------\u001b[0m\n",
      "\u001b[32m16:17:48.308\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mrxpy_opkit.logging_ops.logging_operators\u001b[0m - \u001b[1m         Merged: BABABB----------------------------------\u001b[0m\n",
      "\u001b[32m16:17:48.406\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mrxpy_opkit.logging_ops.logging_operators\u001b[0m - \u001b[1m       Stream A: AAA-------------------------------------\u001b[0m\n",
      "\u001b[32m16:17:48.408\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mrxpy_opkit.logging_ops.logging_operators\u001b[0m - \u001b[1m         Merged: BABABBA---------------------------------\u001b[0m\n",
      "\u001b[32m16:17:48.507\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mrxpy_opkit.logging_ops.logging_operators\u001b[0m - \u001b[1m       Stream B: BBBBB-----------------------------------\u001b[0m\n",
      "\u001b[32m16:17:48.510\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mrxpy_opkit.logging_ops.logging_operators\u001b[0m - \u001b[1m         Merged: BABABBAB--------------------------------\u001b[0m\n",
      "\u001b[32m16:17:48.706\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mrxpy_opkit.logging_ops.logging_operators\u001b[0m - \u001b[1m       Stream A: AAAA------------------------------------\u001b[0m\n",
      "\u001b[32m16:17:48.710\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mrxpy_opkit.logging_ops.logging_operators\u001b[0m - \u001b[1m         Merged: BABABBABA-------------------------------\u001b[0m\n",
      "\u001b[32m16:17:48.709\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mrxpy_opkit.logging_ops.logging_operators\u001b[0m - \u001b[1m       Stream B: BBBBBB----------------------------------\u001b[0m\n",
      "\u001b[32m16:17:48.714\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mrxpy_opkit.logging_ops.logging_operators\u001b[0m - \u001b[1m         Merged: BABABBABAB------------------------------\u001b[0m\n",
      "\u001b[32m16:17:48.909\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mrxpy_opkit.logging_ops.logging_operators\u001b[0m - \u001b[1m       Stream B: BBBBBBB---------------------------------\u001b[0m\n",
      "\u001b[32m16:17:48.912\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mrxpy_opkit.logging_ops.logging_operators\u001b[0m - \u001b[1m         Merged: BABABBABABB-----------------------------\u001b[0m\n",
      "\u001b[32m16:17:48.914\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mrxpy_opkit.logging_ops.logging_operators\u001b[0m - \u001b[1m       Stream B: BBBBBBB|-------------------------------- (COMPLETED)\u001b[0m\n",
      "\u001b[32m16:17:49.007\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mrxpy_opkit.logging_ops.logging_operators\u001b[0m - \u001b[1m       Stream A: AAAAA-----------------------------------\u001b[0m\n",
      "\u001b[32m16:17:49.010\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mrxpy_opkit.logging_ops.logging_operators\u001b[0m - \u001b[1m         Merged: BABABBABABBA----------------------------\u001b[0m\n",
      "\u001b[32m16:17:49.012\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mrxpy_opkit.logging_ops.logging_operators\u001b[0m - \u001b[1m       Stream A: AAAAA|---------------------------------- (COMPLETED)\u001b[0m\n",
      "\u001b[32m16:17:49.013\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mrxpy_opkit.logging_ops.logging_operators\u001b[0m - \u001b[1m         Merged: BABABBABABBA|--------------------------- (COMPLETED)\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Compare two different streams\n",
    "stream1 = rx.interval(0.3).pipe(\n",
    "    ops.take(5),\n",
    "    ops.map(lambda x: f\"A{x}\"),\n",
    "    marble_log(\"Stream A\", width=40)\n",
    ")\n",
    "\n",
    "stream2 = rx.interval(0.2).pipe(\n",
    "    ops.take(7),\n",
    "    ops.map(lambda x: f\"B{x}\"),\n",
    "    marble_log(\"Stream B\", width=40)\n",
    ")\n",
    "\n",
    "merged = rx.merge(stream1, stream2).pipe(\n",
    "    marble_log(\"Merged\", width=40)\n",
    ")\n",
    "\n",
    "print(\"\\nExample: Multiple Stream Comparison\")\n",
    "print(\"-----------------------------------\")\n",
    "sub = merged.subscribe()\n",
    "time.sleep(1.8)\n",
    "sub.dispose()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d15d792",
   "metadata": {},
   "source": [
    "## `context_log` - Contextual Logger with Structured Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eb8f61f",
   "metadata": {},
   "source": [
    "### Description and Behavior\n",
    "\n",
    "The `context_log` operator adds rich contextual information to every log entry, including timing, event counts, and custom context fields. Perfect for structured logging and production monitoring.\n",
    "\n",
    "**Behavior Details:**\n",
    "- **On Next**: Logs with event count, elapsed time, value type, and custom context\n",
    "- **On Complete**: Logs with final statistics and elapsed time\n",
    "- **On Error**: Logs with error details and context\n",
    "- **Internal Errors**: None expected (robust error handling)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7bae791-d7ec-4c0f-9d0b-56a1067e10b9",
   "metadata": {
    "title": "Styling"
   },
   "source": [
    "```mermaid\n",
    "flowchart TD\n",
    "    subgraph \"Source Observable\"\n",
    "        SNext[\"on_next: value\"]\n",
    "        SComplete[\"on_completed\"]\n",
    "        SError[\"on_error: err\"]\n",
    "    end\n",
    "    \n",
    "    subgraph \"context_log Operator\"\n",
    "        BindContext[\"Bind logger with<br/>operator name & context\"]\n",
    "        CalcElapsed[\"Calculate elapsed time<br/>since start\"]\n",
    "        IncrementCount[\"Increment event counter\"]\n",
    "        LogWithContext[\"Log with:<br/>• event type<br/>• count<br/>• elapsed time<br/>• value type<br/>• custom context\"]\n",
    "    end\n",
    "    \n",
    "    subgraph \"Subscriber\"\n",
    "        ONext[\"on_next: value<br/>(unchanged)\"]\n",
    "        OComplete[\"on_completed\"]\n",
    "        OError[\"on_error: err\"]\n",
    "    end\n",
    "    \n",
    "\n",
    "    SNext --> IncrementCount\n",
    "    IncrementCount --> CalcElapsed\n",
    "    CalcElapsed --> LogWithContext\n",
    "    LogWithContext --> ONext\n",
    "    \n",
    "\n",
    "    SComplete --> CalcElapsed\n",
    "    CalcElapsed --> LogWithContext\n",
    "    LogWithContext --> OComplete\n",
    "    \n",
    "\n",
    "    SError --> CalcElapsed\n",
    "    CalcElapsed --> LogWithContext\n",
    "    LogWithContext --> OError\n",
    "    \n",
    "\n",
    "    style SNext fill:#e4f7fb,stroke:#333\n",
    "    style SComplete fill:#e4f7fb,stroke:#333\n",
    "    style SError fill:#e4f7fb,stroke:#333\n",
    "    \n",
    "    style BindContext fill:#f96,stroke:#333\n",
    "    style CalcElapsed fill:#f96,stroke:#333\n",
    "    style IncrementCount fill:#f96,stroke:#333\n",
    "    style LogWithContext fill:#f96,stroke:#333\n",
    "    \n",
    "    style ONext fill:#d5f5d5,stroke:#333\n",
    "    style OComplete fill:#d5f5d5,stroke:#333\n",
    "    style OError fill:#ffcccc,stroke:#333\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e46c39c3",
   "metadata": {},
   "source": [
    "### When to Use/Avoid and Alternatives"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42aee751",
   "metadata": {},
   "source": [
    "**When to Use:**\n",
    "- Production logging with structured data\n",
    "- Tracking request/response flows with correlation IDs\n",
    "- Performance monitoring with business context\n",
    "- Debugging complex multi-step processes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b89e3acc",
   "metadata": {},
   "source": [
    "**When to Avoid:**\n",
    "- Simple debugging (use `log` instead)\n",
    "- When you don't need structured data\n",
    "- High-frequency streams without sampling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d78cf57",
   "metadata": {},
   "source": [
    "**Alternatives:**\n",
    "- `log`: For simple debugging without structure\n",
    "- Custom `do_action`: For specific logging requirements\n",
    "- External APM tools for production monitoring"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db626403",
   "metadata": {},
   "source": [
    "### Nominal Usage Examples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b3f0bc8",
   "metadata": {},
   "source": [
    "#### API Request Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c4e2d8c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example: API Request Context Logging\n",
      "-----------------------------------\n",
      "\u001b[32m16:17:49.416\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mrxpy_opkit.logging_ops.logging_operators\u001b[0m - \u001b[1mValue: {'step': 'validate', 'status': 'ok'}\u001b[0m\n",
      "\u001b[32m16:17:49.418\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mrxpy_opkit.logging_ops.logging_operators\u001b[0m - \u001b[1mValue: {'step': 'authorize', 'status': 'ok'}\u001b[0m\n",
      "\u001b[32m16:17:49.419\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mrxpy_opkit.logging_ops.logging_operators\u001b[0m - \u001b[1mValue: {'step': 'process', 'status': 'ok'}\u001b[0m\n",
      "\u001b[32m16:17:49.420\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mrxpy_opkit.logging_ops.logging_operators\u001b[0m - \u001b[1mValue: {'step': 'respond', 'status': 'ok'}\u001b[0m\n",
      "\u001b[32m16:17:49.421\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mrxpy_opkit.logging_ops.logging_operators\u001b[0m - \u001b[1mCompleted\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Simulate API request processing with context\n",
    "def process_request(request_id):\n",
    "    return rx.of(\n",
    "        {\"step\": \"validate\", \"status\": \"ok\"},\n",
    "        {\"step\": \"authorize\", \"status\": \"ok\"},\n",
    "        {\"step\": \"process\", \"status\": \"ok\"},\n",
    "        {\"step\": \"respond\", \"status\": \"ok\"}\n",
    "    ).pipe(\n",
    "        ops.delay(0.1),\n",
    "        context_log(\"RequestProcessor\", \n",
    "                   request_id=request_id,\n",
    "                   user_id=\"user123\",\n",
    "                   endpoint=\"/api/orders\")\n",
    "    )\n",
    "\n",
    "print(\"Example: API Request Context Logging\")\n",
    "print(\"-----------------------------------\")\n",
    "process_request(\"req-12345\").subscribe()\n",
    "time.sleep(0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16a1998f",
   "metadata": {},
   "source": [
    "#### Multi-Service Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2d064dc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Example: Multi-Service Pipeline\n",
      "-------------------------------\n",
      "\u001b[32m16:17:49.829\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mrxpy_opkit.logging_ops.logging_operators\u001b[0m - \u001b[1mValue: {'order_id': 'ORD-789', 'customer_id': 'CUST-456', 'total': 150.0, 'items': ['item1', 'item2', 'item3']}\u001b[0m\n",
      "\u001b[32m16:17:49.829\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mrxpy_opkit.logging_ops.logging_operators\u001b[0m - \u001b[1mValue: {'order_id': 'ORD-789', 'customer_id': 'CUST-456', 'total': 150.0, 'items': ['item1', 'item2', 'item3'], 'validated': True}\u001b[0m\n",
      "\u001b[32m16:17:49.830\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mrxpy_opkit.logging_ops.logging_operators\u001b[0m - \u001b[1mValue: {'order_id': 'ORD-789', 'customer_id': 'CUST-456', 'total': 150.0, 'items': ['item1', 'item2', 'item3'], 'validated': True, 'payment_id': 'PAY-ORD-789'}\u001b[0m\n",
      "\u001b[32m16:17:49.830\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mrxpy_opkit.logging_ops.logging_operators\u001b[0m - \u001b[1mCompleted\u001b[0m\n",
      "\u001b[32m16:17:49.830\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mrxpy_opkit.logging_ops.logging_operators\u001b[0m - \u001b[1mCompleted\u001b[0m\n",
      "\u001b[32m16:17:49.830\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mrxpy_opkit.logging_ops.logging_operators\u001b[0m - \u001b[1mCompleted\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<reactivex.disposable.disposable.Disposable at 0x77812aa9bad0>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Simulate multi-service data pipeline\n",
    "order_data = {\n",
    "    \"order_id\": \"ORD-789\",\n",
    "    \"customer_id\": \"CUST-456\",\n",
    "    \"total\": 150.00,\n",
    "    \"items\": [\"item1\", \"item2\", \"item3\"]\n",
    "}\n",
    "\n",
    "pipeline = rx.of(order_data).pipe(\n",
    "    context_log(\"OrderService\", service=\"order\", environment=\"prod\"),\n",
    "    ops.map(lambda order: {**order, \"validated\": True}),\n",
    "    context_log(\"ValidationService\", service=\"validation\", environment=\"prod\"),\n",
    "    ops.map(lambda order: {**order, \"payment_id\": \"PAY-\" + order[\"order_id\"]}),\n",
    "    context_log(\"PaymentService\", service=\"payment\", environment=\"prod\")\n",
    ")\n",
    "\n",
    "print(\"\\nExample: Multi-Service Pipeline\")\n",
    "print(\"-------------------------------\")\n",
    "pipeline.subscribe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fd3f40e",
   "metadata": {},
   "source": [
    "## `rich_log` - Rich Formatting Logger"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcb64f15",
   "metadata": {},
   "source": [
    "### Description and Behavior\n",
    "\n",
    "The `rich_log` operator provides enhanced formatting for different data types with color coding and special formatting for collections, numbers, and complex objects.\n",
    "\n",
    "**Behavior Details:**\n",
    "- **On Next**: Formats values based on type with colors and structure\n",
    "- **On Complete**: Shows completion with item count in green\n",
    "- **On Error**: Shows errors in red with highlighting\n",
    "- **Internal Errors**: Gracefully handles formatting failures"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c533e968",
   "metadata": {},
   "source": [
    "### Nominal Usage Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2e848aa4",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example: Rich Formatted Logging\n",
      "-------------------------------\n",
      "\u001b[32m16:17:49.835\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mrxpy_opkit.logging_ops.logging_operators\u001b[0m - \u001b[1m\u001b[33m[DataStream]\u001b[0m\u001b[1m Number: \u001b[32m42\u001b[0m\u001b[1m \u001b[2m(int)\u001b[0m\u001b[1m\u001b[0m\n",
      "\u001b[32m16:17:49.835\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mrxpy_opkit.logging_ops.logging_operators\u001b[0m - \u001b[1m\u001b[33m[DataStream]\u001b[0m\u001b[1m Number: \u001b[31m-15\u001b[0m\u001b[1m \u001b[2m(int)\u001b[0m\u001b[1m\u001b[0m\n",
      "\u001b[32m16:17:49.835\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mrxpy_opkit.logging_ops.logging_operators\u001b[0m - \u001b[1m\u001b[33m[DataStream]\u001b[0m\u001b[1m Number: \u001b[34m0\u001b[0m\u001b[1m \u001b[2m(int)\u001b[0m\u001b[1m\u001b[0m\n",
      "\u001b[33m[DataStream]\u001b[0m Dict: {\u001b[34mname\u001b[0m: Alice, \u001b[34mage\u001b[0m: 30, \u001b[34mcity\u001b[0m: NYC}\u001b[32m16:17:49.836\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mrxpy_opkit.logging_ops.logging_operators\u001b[0m - \u001b[1m\u001b[33m[DataStream]\u001b[0m\u001b[1m List: \u001b[35m[apple, banana, cherry, date, elderberry... (6 total)]\u001b[0m\u001b[1m\u001b[0m\n",
      "\u001b[32m16:17:49.836\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mrxpy_opkit.logging_ops.logging_operators\u001b[0m - \u001b[1m\u001b[33m[DataStream]\u001b[0m\u001b[1m Value: Simple string \u001b[2m(str)\u001b[0m\u001b[1m\u001b[0m\n",
      "\u001b[32m16:17:49.836\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mrxpy_opkit.logging_ops.logging_operators\u001b[0m - \u001b[1m\u001b[33m[DataStream]\u001b[0m\u001b[1m Number: \u001b[32m3.14159\u001b[0m\u001b[1m \u001b[2m(float)\u001b[0m\u001b[1m\u001b[0m\n",
      "\u001b[33m[DataStream]\u001b[0m Dict (6 items):\n",
      "  - \u001b[34ma\u001b[0m: 1\n",
      "  - \u001b[34mb\u001b[0m: 2\n",
      "  - \u001b[34mc\u001b[0m: 3\n",
      "  - \u001b[34md\u001b[0m: 4\n",
      "  - \u001b[34me\u001b[0m: 5\n",
      "  ... and 1 more items\u001b[32m16:17:49.837\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[36mrxpy_opkit.logging_ops.logging_operators\u001b[0m - \u001b[32m\u001b[1m\u001b[33m[DataStream]\u001b[0m\u001b[32m\u001b[1m \u001b[32mCOMPLETED\u001b[0m\u001b[32m\u001b[1m after 8 items\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<reactivex.disposable.disposable.Disposable at 0x77812aa9b770>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example with various data types\n",
    "mixed_data = rx.of(\n",
    "    42,\n",
    "    -15,\n",
    "    0,\n",
    "    {\"name\": \"Alice\", \"age\": 30, \"city\": \"NYC\"},\n",
    "    [\"apple\", \"banana\", \"cherry\", \"date\", \"elderberry\", \"fig\"],\n",
    "    \"Simple string\",\n",
    "    3.14159,\n",
    "    {\"a\": 1, \"b\": 2, \"c\": 3, \"d\": 4, \"e\": 5, \"f\": 6}\n",
    ")\n",
    "\n",
    "result = mixed_data.pipe(\n",
    "    rich_log(\"DataStream\", colorize=True, show_type=True)\n",
    ")\n",
    "\n",
    "print(\"Example: Rich Formatted Logging\")\n",
    "print(\"-------------------------------\")\n",
    "result.subscribe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54ab7ee2",
   "metadata": {},
   "source": [
    "## `perf_log` - Performance Monitoring Logger"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f272a03",
   "metadata": {},
   "source": [
    "### Description and Behavior\n",
    "\n",
    "The `perf_log` operator tracks and logs performance metrics including timing, throughput, and interval statistics. Essential for performance optimization.\n",
    "\n",
    "**Behavior Details:**\n",
    "- **On Next**: Tracks inter-arrival times and counts events\n",
    "- **On Complete**: Logs comprehensive performance statistics\n",
    "- **On Error**: Logs statistics up to the error point\n",
    "- **Internal Errors**: None expected (simple arithmetic)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cd9373a-0bb2-414f-99f5-3ebbc49d7b37",
   "metadata": {
    "title": "Styling"
   },
   "source": [
    "```mermaid\n",
    "flowchart TD\n",
    "    subgraph \"Source Observable\"\n",
    "        SNext[\"on_next: value\"]\n",
    "        SComplete[\"on_completed\"]\n",
    "        SError[\"on_error: err\"]\n",
    "    end\n",
    "    \n",
    "    subgraph \"perf_log Operator\"\n",
    "        RecordTime[\"Record current time\"]\n",
    "        CalcInterval[\"Calculate interval<br/>since last event\"]\n",
    "        StoreInterval[\"Store interval in list\"]\n",
    "        CheckLogInterval[\"Log interval<br/>reached?\"]\n",
    "        CalcStats[\"Calculate:<br/>• avg/min/max interval<br/>• events per second<br/>• total time\"]\n",
    "        LogStats[\"Log performance stats\"]\n",
    "    end\n",
    "    \n",
    "    subgraph \"Subscriber\"\n",
    "        ONext[\"on_next: value<br/>(unchanged)\"]\n",
    "        OComplete[\"on_completed\"]\n",
    "        OError[\"on_error: err\"]\n",
    "    end\n",
    "    \n",
    "\n",
    "    SNext --> RecordTime\n",
    "    RecordTime --> CalcInterval\n",
    "    CalcInterval --> StoreInterval\n",
    "    StoreInterval --> CheckLogInterval\n",
    "    CheckLogInterval -->|Yes| CalcStats\n",
    "    CheckLogInterval -->|No| ONext\n",
    "    CalcStats --> LogStats\n",
    "    LogStats --> ONext\n",
    "    \n",
    "\n",
    "    SComplete --> CalcStats\n",
    "    CalcStats --> LogStats\n",
    "    LogStats --> OComplete\n",
    "    \n",
    "\n",
    "    SError --> CalcStats\n",
    "    CalcStats --> LogStats\n",
    "    LogStats --> OError\n",
    "    \n",
    "\n",
    "    style SNext fill:#e4f7fb,stroke:#333\n",
    "    style SComplete fill:#e4f7fb,stroke:#333\n",
    "    style SError fill:#e4f7fb,stroke:#333\n",
    "    \n",
    "    style RecordTime fill:#f96,stroke:#333\n",
    "    style CalcInterval fill:#f96,stroke:#333\n",
    "    style StoreInterval fill:#f96,stroke:#333\n",
    "    style CheckLogInterval fill:#f96,stroke:#333\n",
    "    style CalcStats fill:#f96,stroke:#333\n",
    "    style LogStats fill:#f96,stroke:#333\n",
    "    \n",
    "    style ONext fill:#d5f5d5,stroke:#333\n",
    "    style OComplete fill:#d5f5d5,stroke:#333\n",
    "    style OError fill:#ffcccc,stroke:#333\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2f33b27",
   "metadata": {},
   "source": [
    "### When to Use/Avoid and Alternatives"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e4507ff",
   "metadata": {},
   "source": [
    "**When to Use:**\n",
    "- Identifying performance bottlenecks\n",
    "- Monitoring production stream throughput\n",
    "- Comparing operator performance\n",
    "- Capacity planning and optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5adfa830",
   "metadata": {},
   "source": [
    "**When to Avoid:**\n",
    "- Very short streams (statistics not meaningful)\n",
    "- When timing precision isn't important\n",
    "- Development/debugging (use simpler loggers)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bcc024b",
   "metadata": {},
   "source": [
    "**Alternatives:**\n",
    "- `scan` with custom timing logic\n",
    "- External monitoring tools (Prometheus, etc.)\n",
    "- Built-in `timestamp` operator for raw timestamps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51231ff6",
   "metadata": {},
   "source": [
    "### Nominal Usage Examples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3c65540",
   "metadata": {},
   "source": [
    "#### Performance Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0a8833f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example: Performance Monitoring\n",
      "------------------------------\n",
      "\u001b[32m16:17:50.849\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mrxpy_opkit.logging_ops.logging_operators\u001b[0m - \u001b[1mPERF [PROGRESS]: 10 events in 0.907s (11.0/sec) | interval: avg=100.76ms, min=100.43ms, max=100.87ms\u001b[0m\n",
      "\u001b[32m16:17:50.888\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mrxpy_opkit.logging_ops.logging_operators\u001b[0m - \u001b[1mPERF [PROGRESS]: 10 events in 0.935s (10.7/sec) | interval: avg=103.84ms, min=84.37ms, max=124.72ms\u001b[0m\n",
      "\u001b[32m16:17:51.779\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mrxpy_opkit.logging_ops.logging_operators\u001b[0m - \u001b[1mPERF [PROGRESS]: 10 events in 1.826s (5.5/sec) | interval: avg=202.89ms, min=173.85ms, max=228.84ms\u001b[0m\n",
      "\u001b[32m16:17:51.857\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mrxpy_opkit.logging_ops.logging_operators\u001b[0m - \u001b[1mPERF [PROGRESS]: 20 events in 1.915s (10.4/sec) | interval: avg=100.78ms, min=100.43ms, max=100.98ms\u001b[0m\n",
      "\u001b[32m16:17:51.889\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mrxpy_opkit.logging_ops.logging_operators\u001b[0m - \u001b[1mPERF [PROGRESS]: 20 events in 1.936s (10.3/sec) | interval: avg=101.91ms, min=75.59ms, max=136.73ms\u001b[0m\n",
      "\u001b[32m16:17:51.891\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mrxpy_opkit.logging_ops.logging_operators\u001b[0m - \u001b[1mPERF [COMPLETED]: 20 events in 1.949s (10.3/sec) | interval: avg=100.78ms, min=100.43ms, max=100.98ms\u001b[0m\n",
      "\u001b[32m16:17:51.893\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mrxpy_opkit.logging_ops.logging_operators\u001b[0m - \u001b[1mPERF [COMPLETED]: 20 events in 1.940s (10.3/sec) | interval: avg=101.91ms, min=75.59ms, max=136.73ms\u001b[0m\n",
      "\u001b[32m16:17:51.893\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mrxpy_opkit.logging_ops.logging_operators\u001b[0m - \u001b[1mPERF [COMPLETED]: 10 events in 1.941s (5.2/sec) | interval: avg=202.89ms, min=173.85ms, max=228.84ms\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Compare performance of different operators\n",
    "def heavy_computation(x):\n",
    "    # Simulate varying computation time\n",
    "    time.sleep(random.uniform(0.01, 0.05))\n",
    "    return x ** 2\n",
    "\n",
    "# Source with consistent interval\n",
    "source = rx.interval(0.1).pipe(ops.take(20))\n",
    "\n",
    "# Pipeline with performance monitoring\n",
    "pipeline = source.pipe(\n",
    "    perf_log(\"Source\", log_interval=10),\n",
    "    ops.map(heavy_computation),\n",
    "    perf_log(\"After Heavy Computation\", log_interval=10),\n",
    "    ops.filter(lambda x: x % 2 == 0),\n",
    "    perf_log(\"After Filter\", log_interval=10)\n",
    ")\n",
    "\n",
    "print(\"Example: Performance Monitoring\")\n",
    "print(\"------------------------------\")\n",
    "sub = pipeline.subscribe()\n",
    "time.sleep(2.5)\n",
    "sub.dispose()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03f4c0dd",
   "metadata": {},
   "source": [
    "#### Batch Processing Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cda99ce5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Example: Batch Processing Performance\n",
      "------------------------------------\n",
      "\u001b[32m16:17:53.354\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mrxpy_opkit.logging_ops.logging_operators\u001b[0m - \u001b[1mPERF [PROGRESS]: 20 events in 0.501s (40.0/sec) | interval: avg=26.34ms, min=0.00ms, max=500.40ms\u001b[0m\n",
      "\u001b[32m16:17:54.356\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mrxpy_opkit.logging_ops.logging_operators\u001b[0m - \u001b[1mPERF [PROGRESS]: 40 events in 1.502s (26.6/sec) | interval: avg=38.51ms, min=0.00ms, max=500.77ms\u001b[0m\n",
      "\u001b[32m16:17:54.857\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mrxpy_opkit.logging_ops.logging_operators\u001b[0m - \u001b[1mPERF [COMPLETED]: 5 events in 2.004s (2.5/sec) | interval: avg=500.72ms, min=500.64ms, max=500.87ms\u001b[0m\n",
      "\u001b[32m16:17:54.859\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mrxpy_opkit.logging_ops.logging_operators\u001b[0m - \u001b[1mPERF [COMPLETED]: 50 events in 2.005s (24.9/sec) | interval: avg=40.87ms, min=0.00ms, max=500.77ms\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Monitor batch processing performance\n",
    "batches = rx.interval(0.5).pipe(\n",
    "    ops.take(5),\n",
    "    ops.map(lambda i: list(range(i * 10, (i + 1) * 10))),\n",
    "    perf_log(\"Batch Generator\"),\n",
    "    ops.flat_map(lambda batch: rx.from_(batch)),\n",
    "    ops.scan(lambda acc, x: acc + x, 0),\n",
    "    perf_log(\"Accumulator\", log_interval=20)\n",
    ")\n",
    "\n",
    "print(\"\\nExample: Batch Processing Performance\")\n",
    "print(\"------------------------------------\")\n",
    "sub = batches.subscribe(on_next=lambda x: None)  # Suppress output\n",
    "time.sleep(3)\n",
    "sub.dispose()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dd2854c",
   "metadata": {},
   "source": [
    "## `conditional_log` - Filtered Logging Operator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff3f46f4",
   "metadata": {},
   "source": [
    "### Description and Behavior\n",
    "\n",
    "The `conditional_log` operator only logs events that meet specified criteria, reducing log volume while maintaining visibility into important events.\n",
    "\n",
    "**Behavior Details:**\n",
    "- **On Next**: Logs only if value predicate returns True\n",
    "- **On Complete**: Logs summary of logged vs total events\n",
    "- **On Error**: Logs only if error predicate returns True\n",
    "- **Internal Errors**: Predicate exceptions are handled gracefully"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9366715e",
   "metadata": {},
   "source": [
    "### Nominal Usage Examples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7863198e",
   "metadata": {},
   "source": [
    "#### Log Only Errors and Warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d77641a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example: Conditional Error Logging\n",
      "---------------------------------\n",
      "\u001b[32m16:17:55.366\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mrxpy_opkit.logging_ops.logging_operators\u001b[0m - \u001b[33m\u001b[1mValue: {'status': 404, 'error': 'not found'} (logged 1/2, 50.0%)\u001b[0m\n",
      "\u001b[32m16:17:55.369\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mrxpy_opkit.logging_ops.logging_operators\u001b[0m - \u001b[33m\u001b[1mValue: {'status': 500, 'error': 'server error'} (logged 2/4, 50.0%)\u001b[0m\n",
      "\u001b[32m16:17:55.371\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mrxpy_opkit.logging_ops.logging_operators\u001b[0m - \u001b[33m\u001b[1mValue: {'status': 403, 'error': 'forbidden'} (logged 3/6, 50.0%)\u001b[0m\n",
      "\u001b[32m16:17:55.373\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mrxpy_opkit.logging_ops.logging_operators\u001b[0m - \u001b[1mCompleted. Logged 3/6 values (50.0%)\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<reactivex.disposable.disposable.Disposable at 0x77812aa9a030>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Stream with mixed success/error responses\n",
    "responses = rx.from_([\n",
    "    {\"status\": 200, \"data\": \"ok\"},\n",
    "    {\"status\": 404, \"error\": \"not found\"},\n",
    "    {\"status\": 200, \"data\": \"ok\"},\n",
    "    {\"status\": 500, \"error\": \"server error\"},\n",
    "    {\"status\": 200, \"data\": \"ok\"},\n",
    "    {\"status\": 403, \"error\": \"forbidden\"}\n",
    "])\n",
    "\n",
    "# Only log errors\n",
    "error_responses = responses.pipe(\n",
    "    conditional_log(\n",
    "        \"ErrorMonitor\",\n",
    "        value_predicate=lambda r: r.get(\"status\", 200) >= 400,\n",
    "        log_level=\"WARNING\"\n",
    "    )\n",
    ")\n",
    "\n",
    "print(\"Example: Conditional Error Logging\")\n",
    "print(\"---------------------------------\")\n",
    "error_responses.subscribe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0740bb42",
   "metadata": {},
   "source": [
    "#### High-Value Transaction Logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "440e22c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Example: High-Value Transaction Monitoring\n",
      "-----------------------------------------\n",
      "\u001b[32m16:17:55.385\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mrxpy_opkit.logging_ops.logging_operators\u001b[0m - \u001b[1mValue: {'id': 2, 'amount': 1500.0, 'type': 'purchase'} (logged 1/2, 50.0%)\u001b[0m\n",
      "\u001b[32m16:17:55.386\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mrxpy_opkit.logging_ops.logging_operators\u001b[0m - \u001b[1mValue: {'id': 4, 'amount': 5000.0, 'type': 'purchase'} (logged 2/4, 50.0%)\u001b[0m\n",
      "\u001b[32m16:17:55.386\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mrxpy_opkit.logging_ops.logging_operators\u001b[0m - \u001b[1mCompleted. Logged 2/5 values (40.0%)\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<reactivex.disposable.disposable.Disposable at 0x77812aa99610>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Stream of transactions\n",
    "transactions = rx.from_([\n",
    "    {\"id\": 1, \"amount\": 10.50, \"type\": \"purchase\"},\n",
    "    {\"id\": 2, \"amount\": 1500.00, \"type\": \"purchase\"},\n",
    "    {\"id\": 3, \"amount\": 25.00, \"type\": \"refund\"},\n",
    "    {\"id\": 4, \"amount\": 5000.00, \"type\": \"purchase\"},\n",
    "    {\"id\": 5, \"amount\": 75.00, \"type\": \"purchase\"},\n",
    "])\n",
    "\n",
    "# Only log high-value transactions\n",
    "high_value = transactions.pipe(\n",
    "    conditional_log(\n",
    "        \"HighValueMonitor\",\n",
    "        value_predicate=lambda t: t[\"amount\"] > 1000,\n",
    "        summarize=True\n",
    "    )\n",
    ")\n",
    "\n",
    "print(\"\\nExample: High-Value Transaction Monitoring\")\n",
    "print(\"-----------------------------------------\")\n",
    "high_value.subscribe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50f1ff1a",
   "metadata": {},
   "source": [
    "## Helper Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b77880cd",
   "metadata": {},
   "source": [
    "### `debug_stream` - Quick Debugging Helper"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74af8283",
   "metadata": {},
   "source": [
    "#### Description\n",
    "\n",
    "A convenience function that uses `do_action` to quickly add debug logging at any point in a pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4f11d51e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m16:17:55.391\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mrxpy_opkit.logging_ops.logging_operators\u001b[0m - \u001b[1mCompleted\u001b[0m\n",
      "\u001b[32m16:17:55.391\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mrxpy_opkit.logging_ops.logging_operators\u001b[0m - \u001b[1mCompleted\u001b[0m\n",
      "\u001b[32m16:17:55.391\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mrxpy_opkit.logging_ops.logging_operators\u001b[0m - \u001b[1mCompleted\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<reactivex.disposable.disposable.Disposable at 0x77812aac96d0>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Quick debugging example\n",
    "rx.range(1, 5).pipe(\n",
    "    debug_stream(\"Input\"),\n",
    "    ops.map(lambda x: x ** 2),\n",
    "    debug_stream(\"Squared\"),\n",
    "    ops.filter(lambda x: x > 5),\n",
    "    debug_stream(\"Filtered\")\n",
    ").subscribe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb03aaf7",
   "metadata": {},
   "source": [
    "### `timestamp_stream` - Timing Helper"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9760dcc1",
   "metadata": {},
   "source": [
    "#### Description\n",
    "\n",
    "Adds elapsed time information to log messages, useful for understanding timing in async operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e31423a8",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m16:17:55.595\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mrxpy_opkit.logging_ops.logging_operators\u001b[0m - \u001b[1m[0.201s] Next: int\u001b[0m\n",
      "\u001b[32m16:17:55.698\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mrxpy_opkit.logging_ops.logging_operators\u001b[0m - \u001b[1m[0.304s] Next: int\u001b[0m\n",
      "\u001b[32m16:17:55.700\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mrxpy_opkit.logging_ops.logging_operators\u001b[0m - \u001b[1m[0.306s] Next: int\u001b[0m\n",
      "\u001b[32m16:17:55.796\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mrxpy_opkit.logging_ops.logging_operators\u001b[0m - \u001b[1m[0.401s] Next: int\u001b[0m\n",
      "\u001b[32m16:17:55.900\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mrxpy_opkit.logging_ops.logging_operators\u001b[0m - \u001b[1m[0.505s] Next: int\u001b[0m\n",
      "\u001b[32m16:17:55.902\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mrxpy_opkit.logging_ops.logging_operators\u001b[0m - \u001b[1m[0.508s] Next: int\u001b[0m\n",
      "\u001b[32m16:17:55.996\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mrxpy_opkit.logging_ops.logging_operators\u001b[0m - \u001b[1m[0.602s] Next: int\u001b[0m\n",
      "\u001b[32m16:17:56.100\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mrxpy_opkit.logging_ops.logging_operators\u001b[0m - \u001b[1m[0.706s] Next: int\u001b[0m\n",
      "\u001b[32m16:17:56.102\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mrxpy_opkit.logging_ops.logging_operators\u001b[0m - \u001b[1m[0.708s] Next: int\u001b[0m\n",
      "\u001b[32m16:17:56.197\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mrxpy_opkit.logging_ops.logging_operators\u001b[0m - \u001b[1m[0.802s] Next: int\u001b[0m\n",
      "\u001b[32m16:17:56.299\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mrxpy_opkit.logging_ops.logging_operators\u001b[0m - \u001b[1m[0.905s] Next: int\u001b[0m\n",
      "\u001b[32m16:17:56.302\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mrxpy_opkit.logging_ops.logging_operators\u001b[0m - \u001b[1m[0.907s] Next: int\u001b[0m\n",
      "\u001b[32m16:17:56.397\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mrxpy_opkit.logging_ops.logging_operators\u001b[0m - \u001b[1m[1.003s] Next: int\u001b[0m\n",
      "\u001b[32m16:17:56.401\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[36mrxpy_opkit.logging_ops.logging_operators\u001b[0m - \u001b[32m\u001b[1m[1.006s] Completed\u001b[0m\n",
      "\u001b[32m16:17:56.501\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mrxpy_opkit.logging_ops.logging_operators\u001b[0m - \u001b[1m[1.106s] Next: int\u001b[0m\n",
      "\u001b[32m16:17:56.503\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mrxpy_opkit.logging_ops.logging_operators\u001b[0m - \u001b[1m[1.109s] Next: int\u001b[0m\n",
      "\u001b[32m16:17:56.504\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[36mrxpy_opkit.logging_ops.logging_operators\u001b[0m - \u001b[32m\u001b[1m[1.110s] Completed\u001b[0m\n",
      "\u001b[32m16:17:56.506\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[36mrxpy_opkit.logging_ops.logging_operators\u001b[0m - \u001b[32m\u001b[1m[1.112s] Completed\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Timing analysis example\n",
    "rx.interval(0.2).pipe(\n",
    "    ops.take(5),\n",
    "    timestamp_stream(\"Start\"),\n",
    "    ops.delay(0.1),\n",
    "    timestamp_stream(\"After Delay\"),\n",
    "    ops.scan(lambda acc, x: acc + x, 0),\n",
    "    timestamp_stream(\"After Scan\")\n",
    ").subscribe(on_next=lambda x: None)\n",
    "\n",
    "time.sleep(1.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "849df8be",
   "metadata": {},
   "source": [
    "## Best Practices and Tips"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03b60ce8",
   "metadata": {},
   "source": [
    "### 1. **Choose the Right Logger**\n",
    "- `log`: Basic debugging\n",
    "- `marble_log`: Timing visualization\n",
    "- `context_log`: Production structured logging\n",
    "- `rich_log`: Complex data inspection\n",
    "- `perf_log`: Performance analysis\n",
    "- `conditional_log`: High-volume stream filtering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eadf3eb6",
   "metadata": {},
   "source": [
    "### 2. **Performance Considerations**\n",
    "```python\n",
    "# Bad: Logging everything in high-frequency stream\n",
    "rx.interval(0.001).pipe(\n",
    "    log(\"Too Much!\")  # Don't do this!\n",
    ")\n",
    "\n",
    "# Good: Sample or filter before logging\n",
    "rx.interval(0.001).pipe(\n",
    "    ops.sample(1.0),  # Sample once per second\n",
    "    log(\"Sampled\")\n",
    ")\n",
    "\n",
    "# Better: Use conditional logging\n",
    "rx.interval(0.001).pipe(\n",
    "    ops.scan(lambda acc, x: acc + 1, 0),\n",
    "    conditional_log(\"Every100th\", \n",
    "                   value_predicate=lambda x: x % 100 == 0)\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d18c55d",
   "metadata": {},
   "source": [
    "### 3. **Combining Loggers**\n",
    "```python\n",
    "# Use different loggers for different aspects\n",
    "stream.pipe(\n",
    "    context_log(\"Service\", request_id=\"123\"),  # Structure\n",
    "    ops.map(transform),\n",
    "    perf_log(\"Transform\", log_interval=100),   # Performance\n",
    "    ops.filter(validate),\n",
    "    conditional_log(\"Errors\",                   # Errors only\n",
    "                   value_predicate=lambda x: x.get(\"error\"))\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0005a305",
   "metadata": {},
   "source": [
    "### 4. **Production vs Development**\n",
    "```python\n",
    "# Development: verbose logging\n",
    "if DEBUG:\n",
    "    pipeline = source.pipe(\n",
    "        log(\"Debug\"),\n",
    "        marble_log(\"Timing\"),\n",
    "        ops.map(process),\n",
    "        rich_log(\"Results\")\n",
    "    )\n",
    "else:\n",
    "    # Production: selective logging\n",
    "    pipeline = source.pipe(\n",
    "        context_log(\"ProdService\", env=\"prod\"),\n",
    "        ops.map(process),\n",
    "        conditional_log(\"Warnings\", \n",
    "                       value_predicate=lambda x: x.severity > \"INFO\")\n",
    "    )\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "190e79b8",
   "metadata": {},
   "source": [
    "## Error Handling Examples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2ee914c",
   "metadata": {},
   "source": [
    "### Graceful Error Handling in Streams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0d989728",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example: Error Handling with Logging\n",
      "-----------------------------------\n",
      "\u001b[32m16:17:56.905\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mrxpy_opkit.logging_ops.logging_operators\u001b[0m - \u001b[1m[Input] [1] Value: 1\u001b[0m\n",
      "\u001b[32m16:17:56.908\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mrxpy_opkit.logging_ops.logging_operators\u001b[0m - \u001b[1m[Input] [2] Value: 2\u001b[0m\n",
      "\u001b[32m16:17:56.910\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mrxpy_opkit.logging_ops.logging_operators\u001b[0m - \u001b[1m[Input] [3] Value: 3\u001b[0m\n",
      "\u001b[32m16:17:56.911\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mrxpy_opkit.logging_ops.logging_operators\u001b[0m - \u001b[1m[Input] [4] Value: 4\u001b[0m\n",
      "\u001b[32m16:17:56.912\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mrxpy_opkit.logging_ops.logging_operators\u001b[0m - \u001b[1m[Input] [5] Value: 5\u001b[0m\n",
      "\u001b[32m16:17:56.912\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mrxpy_opkit.logging_ops.logging_operators\u001b[0m - \u001b[1m[Input] Completed after 5 values\u001b[0m\n",
      "\u001b[32m16:17:56.914\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mrxpy_opkit.logging_ops.logging_operators\u001b[0m - \u001b[1m[Output] [1] Value: 2\u001b[0m\n",
      "\u001b[32m16:17:56.914\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mrxpy_opkit.logging_ops.logging_operators\u001b[0m - \u001b[1m[Output] [2] Value: 4\u001b[0m\n",
      "\u001b[32m16:17:56.915\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mrxpy_opkit.logging_ops.logging_operators\u001b[0m - \u001b[1m[Output] [3] Value: 8\u001b[0m\n",
      "\u001b[32m16:17:56.915\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mrxpy_opkit.logging_ops.logging_operators\u001b[0m - \u001b[1m[Output] [4] Value: 10\u001b[0m\n",
      "\u001b[32m16:17:56.916\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mrxpy_opkit.logging_ops.logging_operators\u001b[0m - \u001b[1m[Output] [5] Value: ERROR: Cannot process 3\u001b[0m\n",
      "\u001b[32m16:17:56.916\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mrxpy_opkit.logging_ops.logging_operators\u001b[0m - \u001b[1m[Output] Completed after 5 values\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<reactivex.disposable.disposable.Disposable at 0x77812aac97f0>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Stream that might have errors\n",
    "def risky_operation(x):\n",
    "    if x == 3:\n",
    "        raise ValueError(f\"Cannot process {x}\")\n",
    "    return x * 2\n",
    "\n",
    "source = rx.from_([1, 2, 3, 4, 5])\n",
    "\n",
    "# Log errors without stopping the stream\n",
    "result = source.pipe(\n",
    "    log(\"Input\"),\n",
    "    ops.map(lambda x: rx.just(x).pipe(\n",
    "        ops.map(risky_operation),\n",
    "        ops.catch(lambda e, src: rx.of(f\"ERROR: {e}\"))\n",
    "    )),\n",
    "    ops.merge_all(),\n",
    "    log(\"Output\"),\n",
    ")\n",
    "\n",
    "print(\"Example: Error Handling with Logging\")\n",
    "print(\"-----------------------------------\")\n",
    "result.subscribe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5c98c71",
   "metadata": {},
   "source": [
    "### Performance Impact of Logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "62aca0f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Performance Impact of Logging:\n",
      "Without logging: 0.0749s\n",
      "With logging: 0.0900s\n",
      "Overhead: 20.1%\n"
     ]
    }
   ],
   "source": [
    "# Demonstrate performance impact\n",
    "import timeit\n",
    "\n",
    "def no_logging():\n",
    "    rx.range(1000).pipe(\n",
    "        ops.map(lambda x: x * 2),\n",
    "        ops.filter(lambda x: x % 2 == 0)\n",
    "    ).subscribe(on_next=lambda x: None)\n",
    "\n",
    "def with_logging():\n",
    "    rx.range(1000).pipe(\n",
    "        log(\"Input\", log_values=True, log_completion=False),\n",
    "        ops.map(lambda x: x * 2),\n",
    "        log(\"Mapped\", log_values=True, log_completion=False),\n",
    "        ops.filter(lambda x: x % 2 == 0),\n",
    "        log(\"Filtered\", log_values=True, log_completion=False)\n",
    "    ).subscribe(on_next=lambda x: None)\n",
    "\n",
    "# Temporarily suppress logging output for timing\n",
    "logger.remove()\n",
    "\n",
    "no_log_time = timeit.timeit(no_logging, number=10)\n",
    "with_log_time = timeit.timeit(with_logging, number=10)\n",
    "\n",
    "# Re-enable logging\n",
    "logger.add(sys.stdout, level=\"INFO\")\n",
    "\n",
    "print(f\"\\nPerformance Impact of Logging:\")\n",
    "print(f\"Without logging: {no_log_time:.4f}s\")\n",
    "print(f\"With logging: {with_log_time:.4f}s\")\n",
    "print(f\"Overhead: {((with_log_time - no_log_time) / no_log_time) * 100:.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d9c0cab",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "The RxPy OpKit logging operators provide a comprehensive toolkit for debugging and monitoring reactive streams:\n",
    "\n",
    "1. **Basic Logging** (`log`) - Simple, effective debugging\n",
    "2. **Visual Logging** (`marble_log`) - ASCII marble diagrams\n",
    "3. **Structured Logging** (`context_log`) - Production-ready with context\n",
    "4. **Pretty Logging** (`rich_log`) - Enhanced formatting for complex data\n",
    "5. **Performance Logging** (`perf_log`) - Detailed timing analysis\n",
    "6. **Filtered Logging** (`conditional_log`) - Reduce log volume intelligently\n",
    "\n",
    "Choose the right logger for your use case and remember to consider performance impacts in production environments."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "678a7840",
   "metadata": {},
   "source": [
    "### Documentation and Reference Links\n",
    "\n",
    "- [RxPy OpKit GitHub Repository](#) - Source code and examples\n",
    "- [RxPy Documentation](https://rxpy.readthedocs.io/) - Official RxPy docs\n",
    "- [Loguru Documentation](https://loguru.readthedocs.io/) - Logging library used\n",
    "- [Reactive Extensions](http://reactivex.io/) - ReactiveX concepts and patterns"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "title,-all",
   "formats": "ipynb,py:percent"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
